# Web-scrapping ğŸ“šğŸ

## ğŸ‡§ğŸ‡· PortuguÃªs

Este projeto visa o entendimento do web-scrapping. Utilizando uma analogia bÃ¡sica do robÃ´ cansado de copiar e colar:
Imagine que vocÃª quer criar uma planilha com o nome e o preÃ§o de todos os videogames da primeira pÃ¡gina de um site de vendas.

O jeito manual: VocÃª abre o site, encontra o primeiro videogame, seleciona o nome, `Ctrl+C`. Vai para a sua planilha, `Ctrl+V`. Volta pro site, seleciona o preÃ§o, `Ctrl+C`. Vai para a planilha, `Ctrl+V`. Repete isso para o segundo, o terceiro... o quinquagÃ©simo videogame. Chato, nÃ©? Lento, cansativo e fÃ¡cil de cometer erros.

O jeito Web Scraping: Agora, imagine que vocÃª pode programar um "robÃ´" (um script em Python) e dar a ele uma Ãºnica ordem: "RobÃ´, vÃ¡ atÃ© este site, encontre a Ã¡rea onde estÃ£o os videogames e, para cada um deles, pegue o nome e o preÃ§o e me traga tudo organizado em uma lista."

O robÃ´ faz isso em segundos, sem reclamar e sem erros.

### DescriÃ§Ã£o do Projeto
Este Ã© um script em Python que realiza web scraping no portal CERT.br para coletar as publicaÃ§Ãµes mais recentes sobre seguranÃ§a digital. Ele extrai tÃ­tulo, resumo e link de cada publicaÃ§Ã£o, realiza um processo de limpeza dos dados textuais, corrige links relativos e, por fim, exibe as informaÃ§Ãµes de forma organizada em uma tabela utilizando a biblioteca Pandas.

## ğŸ‡ºğŸ‡¸ English

This project aims to understand web scraping. Using a basic analogy of the tired copy-paste robot:

Imagine you want to create a spreadsheet with the name and price of every video game on the front page of a retail website.

The manual way: You open the site, find the first video game, select the name, `Ctrl+C`. You go to your spreadsheet, `Ctrl+V`. You go back to the site, select the price, `Ctrl+C`. You go to the spreadsheet, `Ctrl+V`. You repeat this for the second, the third... the fiftieth video game. It's tedious, right? Slow, tiring, and prone to errors.

The Web Scraping way: Now, imagine you can program a "robot" (a Python script) and give it a single command: "Robot, go to this website, find the area where the video games are, and for each one, grab the name and the price and bring them all back to me in an organized list."

The robot does this in seconds, without complaining and without errors.

### Project Description
This is a Python script that performs web scraping on the CERT.br portal to collect the latest publications on digital security. It extracts the title, summary, and link for each publication, performs a cleaning process on the textual data, corrects relative links, and finally, displays the information in an organized table using the Pandas library.

---

# ğŸš€ Funcionalidades Principais (Features)
âœ… Coleta automatizada de dados do portal de publicaÃ§Ãµes do CERT.br.

âœ… ExtraÃ§Ã£o de informaÃ§Ãµes especÃ­ficas: TÃ­tulo, resumo e link de cada artigo.

âœ… Limpeza e tratamento dos dados para remover quebras de linha e espaÃ§os desnecessÃ¡rios.

âœ… CorreÃ§Ã£o automÃ¡tica de links relativos para links absolutos e funcionais.

âœ… ApresentaÃ§Ã£o profissional dos dados em um DataFrame (tabela) com Pandas.

# ğŸ› ï¸ Tecnologias Utilizadas (Tech Stack)
Linguagem: Python

Bibliotecas:

`requests` para realizar as requisiÃ§Ãµes HTTP.

`Beautiful Soup 4` para fazer o parse do HTML.

`Pandas` para a estruturaÃ§Ã£o e exibiÃ§Ã£o dos dados.

---

âš™ï¸ Como Executar o Projeto (Getting Started)
Siga os passos abaixo para executar o projeto em sua mÃ¡quina local.

### 1. Clone o RepositÃ³rio
- git clone https://github.com/jyxx-1/web-scrapping.git
- cd web-scrapping.git

### 2. Crie e Ative o Ambiente Virtual (venv)
- `python -m venv venv`
### 2.1 Ative o Ambiente Virtual (venv)
* Windows:
- `venv\Scripts\activate`
* macOS/Linux:
- `source venv/bin/activate`

### 3. Instale as DependÃªncias

Este projeto utiliza as bibliotecas requests, beautifulsoup4 e pandas. Instale as dependÃªncias a partir do arquivo com o comando:

`pip install -r requirements.txt`

### 4. Execute o Script

Para rodar o scraper e ver o relatÃ³rio de publicaÃ§Ãµes, execute o seguinte comando no terminal:

`python scraper.py`

---

# ğŸ“« Contato
Em caso de dÃºvidas ou sugestÃµes, entre em contato!

- LinkedIn: [JoÃ£o Massari](https://www.linkedin.com/in/joao-paulo-massari-382604278)

- Instagram: @massarii07
